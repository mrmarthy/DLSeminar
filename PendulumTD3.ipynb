{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PendulumTD3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWuLvFW7O9kI",
        "colab_type": "text"
      },
      "source": [
        "#Deep Reinforcement Learning: TD3 in OpenAI Gym - Martin Baur\n",
        "\n",
        "OpenAI Gym: https://gym.openai.com/\n",
        "\n",
        "TD3 Algorithm from stable baselines: https://stable-baselines.readthedocs.io/en/master/modules/td3.html\n",
        "\n",
        "3D environments from pybullet Gym: https://github.com/benelot/pybullet-gym \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd9RaJUFaE-6",
        "colab_type": "text"
      },
      "source": [
        "##Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0mlkK3nZyF4",
        "colab_type": "code",
        "outputId": "53914d3c-56a4-43b0-ca40-5c7c926f8b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "#Workaround to have TD3 available \n",
        "!pip uninstall stable-baselines\n",
        "!pip install stable-baselines[mpi]\n",
        "!pip install pyglet > /dev/null 2>&1\n",
        "!pip install pybullet > /dev/null 2>&1\n",
        "\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "\n",
        "!pip install tensorboard > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling stable-baselines-2.9.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/stable_baselines-2.9.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/stable_baselines/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled stable-baselines-2.9.0\n",
            "Collecting stable-baselines[mpi]\n",
            "  Using cached https://files.pythonhosted.org/packages/c0/05/f6651855083020c0363acf483450c23e38d96f5c18bec8bded113d528da5/stable_baselines-2.9.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.17.5)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.15.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.1.2)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]) (1.12.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]) (6.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]) (45.1.0)\n",
            "Installing collected packages: stable-baselines\n",
            "Successfully installed stable-baselines-2.9.0\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ2w0uSdaNDv",
        "colab_type": "text"
      },
      "source": [
        "##Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZFCfdxUaMUQ",
        "colab_type": "code",
        "outputId": "54abe4a0-a512-49dd-bf1c-08ae876eaa41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import numpy as np\n",
        "import pybullet_envs\n",
        "\n",
        "from stable_baselines import TD3\n",
        "from stable_baselines.td3.policies import MlpPolicy\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiN8AS_GaVCz",
        "colab_type": "text"
      },
      "source": [
        "##Help functions\n",
        "\n",
        "First a Display gets initialized so that an error is avoided\n",
        "\n",
        "Also the help functions for the learning callbacks and Video saving is set up "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxGflo_EaXr0",
        "colab_type": "code",
        "outputId": "498b00f8-c7e6-4565-831c-b4b659bd8c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Defining an display to avoid error\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "#Keeping track of the steps while learning    \n",
        "n_steps = 0\n",
        "\n",
        "def learningCallback(_locals, _globals):\n",
        "    global n_steps\n",
        "    # Save model every 1000 calls\n",
        "    if (n_steps + 1) % 1000 == 0:\n",
        "        model.save(dir_model)\n",
        "    n_steps += 1\n",
        "\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Cnd9VZugO-",
        "colab_type": "text"
      },
      "source": [
        "Mounting Google Drive to save model and videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1wcHuS-LR95",
        "colab_type": "code",
        "outputId": "982a242b-718d-4e45-fed7-1848eb7c02c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdceGcVOLUk6",
        "colab_type": "text"
      },
      "source": [
        "##Defining strings and timesteps\n",
        "\n",
        "Defining the environment strings also the strings for directories in the Google Drive\n",
        "\n",
        "Also the timestep count is defined here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlGiuWt7LXMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#envStrings\n",
        "envPendulum = 'Pendulum-v0'\n",
        "envCheetah = 'HalfCheetah'\n",
        "envAnt = 'AntBulletEnv-v0'\n",
        "envHuman = 'HumanoidBulletEnv-v0'\n",
        "\n",
        "model_string = envPendulum\n",
        "\n",
        "dir = '/content/drive/My Drive/DLSeminar/models/' + model_string + \"/\"\n",
        "\n",
        "dir_logs = dir + 'logs/'\n",
        "\n",
        "dir_model = dir + model_string\n",
        "\n",
        "model_steps = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySOoB9Poaa53",
        "colab_type": "text"
      },
      "source": [
        "##Implementation for the learning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGcNuxjKaZ0r",
        "colab_type": "code",
        "outputId": "1481e18a-ccab-446f-f437-d6117367e229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Creating gym environment\n",
        "env = gym.make(model_string)\n",
        "env = gym.wrappers.Monitor(env, dir + '/video', force=True)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "#Action and noise\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "#creation of the model\n",
        "model = TD3(MlpPolicy, env, action_noise=action_noise, verbose=1, tensorboard_log=dir_logs)\n",
        "\n",
        "#saving model to defined path\n",
        "model.save(dir_model)\n",
        "\n",
        "#loading the model\n",
        "#model = TD3.load(dir_model, env)\n",
        "\n",
        "#start learning\n",
        "model.learn(total_timesteps=model_steps, log_interval=10, callback=learningCallback)\n",
        "\n",
        "obs = env.reset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:136: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/policies.py:125: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/sac/policies.py:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:169: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:199: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:313: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:313: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:214: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:242: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/base_class.py:1082: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/a2c/utils.py:581: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 10        |\n",
            "| fps                     | 101       |\n",
            "| mean 100 episode reward | -1.57e+03 |\n",
            "| n_updates               | 1600      |\n",
            "| qf1_loss                | 2.307422  |\n",
            "| qf2_loss                | 2.231395  |\n",
            "| time_elapsed            | 17        |\n",
            "| total timesteps         | 1800      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 20        |\n",
            "| fps                     | 137       |\n",
            "| mean 100 episode reward | -1.47e+03 |\n",
            "| n_updates               | 3600      |\n",
            "| qf1_loss                | 11.844269 |\n",
            "| qf2_loss                | 12.035159 |\n",
            "| time_elapsed            | 27        |\n",
            "| total timesteps         | 3800      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 30        |\n",
            "| fps                     | 139       |\n",
            "| mean 100 episode reward | -1.38e+03 |\n",
            "| n_updates               | 5600      |\n",
            "| qf1_loss                | 30.447914 |\n",
            "| qf2_loss                | 30.495066 |\n",
            "| time_elapsed            | 41        |\n",
            "| total timesteps         | 5800      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 40        |\n",
            "| fps                     | 150       |\n",
            "| mean 100 episode reward | -1.3e+03  |\n",
            "| n_updates               | 7600      |\n",
            "| qf1_loss                | 55.412617 |\n",
            "| qf2_loss                | 55.425858 |\n",
            "| time_elapsed            | 51        |\n",
            "| total timesteps         | 7800      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 50        |\n",
            "| fps                     | 158       |\n",
            "| mean 100 episode reward | -1.25e+03 |\n",
            "| n_updates               | 9600      |\n",
            "| qf1_loss                | 68.17378  |\n",
            "| qf2_loss                | 68.036095 |\n",
            "| time_elapsed            | 61        |\n",
            "| total timesteps         | 9800      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 60        |\n",
            "| fps                     | 163       |\n",
            "| mean 100 episode reward | -1.2e+03  |\n",
            "| n_updates               | 11600     |\n",
            "| qf1_loss                | 93.770775 |\n",
            "| qf2_loss                | 93.3221   |\n",
            "| time_elapsed            | 71        |\n",
            "| total timesteps         | 11800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 70        |\n",
            "| fps                     | 162       |\n",
            "| mean 100 episode reward | -1.18e+03 |\n",
            "| n_updates               | 13600     |\n",
            "| qf1_loss                | 98.43601  |\n",
            "| qf2_loss                | 98.18157  |\n",
            "| time_elapsed            | 85        |\n",
            "| total timesteps         | 13800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 80        |\n",
            "| fps                     | 165       |\n",
            "| mean 100 episode reward | -1.19e+03 |\n",
            "| n_updates               | 15600     |\n",
            "| qf1_loss                | 157.89993 |\n",
            "| qf2_loss                | 158.80736 |\n",
            "| time_elapsed            | 95        |\n",
            "| total timesteps         | 15800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 90        |\n",
            "| fps                     | 168       |\n",
            "| mean 100 episode reward | -1.15e+03 |\n",
            "| n_updates               | 17600     |\n",
            "| qf1_loss                | 186.17737 |\n",
            "| qf2_loss                | 186.8452  |\n",
            "| time_elapsed            | 105       |\n",
            "| total timesteps         | 17800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 100       |\n",
            "| fps                     | 171       |\n",
            "| mean 100 episode reward | -1.09e+03 |\n",
            "| n_updates               | 19600     |\n",
            "| qf1_loss                | 160.56352 |\n",
            "| qf2_loss                | 160.94217 |\n",
            "| time_elapsed            | 115       |\n",
            "| total timesteps         | 19800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 110       |\n",
            "| fps                     | 173       |\n",
            "| mean 100 episode reward | -988      |\n",
            "| n_updates               | 21600     |\n",
            "| qf1_loss                | 230.77007 |\n",
            "| qf2_loss                | 230.65909 |\n",
            "| time_elapsed            | 125       |\n",
            "| total timesteps         | 21800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 120       |\n",
            "| fps                     | 174       |\n",
            "| mean 100 episode reward | -916      |\n",
            "| n_updates               | 23600     |\n",
            "| qf1_loss                | 187.2381  |\n",
            "| qf2_loss                | 187.91042 |\n",
            "| time_elapsed            | 136       |\n",
            "| total timesteps         | 23800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 130       |\n",
            "| fps                     | 173       |\n",
            "| mean 100 episode reward | -876      |\n",
            "| n_updates               | 25600     |\n",
            "| qf1_loss                | 192.23038 |\n",
            "| qf2_loss                | 192.59659 |\n",
            "| time_elapsed            | 149       |\n",
            "| total timesteps         | 25800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 140       |\n",
            "| fps                     | 174       |\n",
            "| mean 100 episode reward | -821      |\n",
            "| n_updates               | 27600     |\n",
            "| qf1_loss                | 235.52504 |\n",
            "| qf2_loss                | 236.40303 |\n",
            "| time_elapsed            | 159       |\n",
            "| total timesteps         | 27800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 150       |\n",
            "| fps                     | 175       |\n",
            "| mean 100 episode reward | -734      |\n",
            "| n_updates               | 29600     |\n",
            "| qf1_loss                | 290.993   |\n",
            "| qf2_loss                | 291.26364 |\n",
            "| time_elapsed            | 169       |\n",
            "| total timesteps         | 29800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 160       |\n",
            "| fps                     | 177       |\n",
            "| mean 100 episode reward | -664      |\n",
            "| n_updates               | 31600     |\n",
            "| qf1_loss                | 211.75916 |\n",
            "| qf2_loss                | 211.48306 |\n",
            "| time_elapsed            | 179       |\n",
            "| total timesteps         | 31800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 170       |\n",
            "| fps                     | 178       |\n",
            "| mean 100 episode reward | -597      |\n",
            "| n_updates               | 33600     |\n",
            "| qf1_loss                | 180.1682  |\n",
            "| qf2_loss                | 179.77322 |\n",
            "| time_elapsed            | 189       |\n",
            "| total timesteps         | 33800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 180       |\n",
            "| fps                     | 179       |\n",
            "| mean 100 episode reward | -507      |\n",
            "| n_updates               | 35600     |\n",
            "| qf1_loss                | 204.71115 |\n",
            "| qf2_loss                | 204.74081 |\n",
            "| time_elapsed            | 199       |\n",
            "| total timesteps         | 35800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 190       |\n",
            "| fps                     | 179       |\n",
            "| mean 100 episode reward | -445      |\n",
            "| n_updates               | 37600     |\n",
            "| qf1_loss                | 233.56084 |\n",
            "| qf2_loss                | 233.0385  |\n",
            "| time_elapsed            | 210       |\n",
            "| total timesteps         | 37800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 200       |\n",
            "| fps                     | 179       |\n",
            "| mean 100 episode reward | -418      |\n",
            "| n_updates               | 39600     |\n",
            "| qf1_loss                | 203.29102 |\n",
            "| qf2_loss                | 203.3216  |\n",
            "| time_elapsed            | 221       |\n",
            "| total timesteps         | 39800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 210       |\n",
            "| fps                     | 180       |\n",
            "| mean 100 episode reward | -381      |\n",
            "| n_updates               | 41600     |\n",
            "| qf1_loss                | 237.85374 |\n",
            "| qf2_loss                | 237.63963 |\n",
            "| time_elapsed            | 231       |\n",
            "| total timesteps         | 41800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 220       |\n",
            "| fps                     | 179       |\n",
            "| mean 100 episode reward | -336      |\n",
            "| n_updates               | 43600     |\n",
            "| qf1_loss                | 203.73152 |\n",
            "| qf2_loss                | 204.90079 |\n",
            "| time_elapsed            | 244       |\n",
            "| total timesteps         | 43800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 230       |\n",
            "| fps                     | 180       |\n",
            "| mean 100 episode reward | -283      |\n",
            "| n_updates               | 45600     |\n",
            "| qf1_loss                | 125.89255 |\n",
            "| qf2_loss                | 127.35143 |\n",
            "| time_elapsed            | 254       |\n",
            "| total timesteps         | 45800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 240      |\n",
            "| fps                     | 180      |\n",
            "| mean 100 episode reward | -253     |\n",
            "| n_updates               | 47600    |\n",
            "| qf1_loss                | 220.6698 |\n",
            "| qf2_loss                | 220.9332 |\n",
            "| time_elapsed            | 264      |\n",
            "| total timesteps         | 47800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 250       |\n",
            "| fps                     | 180       |\n",
            "| mean 100 episode reward | -255      |\n",
            "| n_updates               | 49600     |\n",
            "| qf1_loss                | 124.9146  |\n",
            "| qf2_loss                | 126.24961 |\n",
            "| time_elapsed            | 275       |\n",
            "| total timesteps         | 49800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 260       |\n",
            "| fps                     | 181       |\n",
            "| mean 100 episode reward | -249      |\n",
            "| n_updates               | 51600     |\n",
            "| qf1_loss                | 202.32703 |\n",
            "| qf2_loss                | 203.44292 |\n",
            "| time_elapsed            | 285       |\n",
            "| total timesteps         | 51800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 270       |\n",
            "| fps                     | 182       |\n",
            "| mean 100 episode reward | -232      |\n",
            "| n_updates               | 53600     |\n",
            "| qf1_loss                | 126.33676 |\n",
            "| qf2_loss                | 127.5647  |\n",
            "| time_elapsed            | 295       |\n",
            "| total timesteps         | 53800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 280       |\n",
            "| fps                     | 182       |\n",
            "| mean 100 episode reward | -248      |\n",
            "| n_updates               | 55600     |\n",
            "| qf1_loss                | 163.34325 |\n",
            "| qf2_loss                | 163.23285 |\n",
            "| time_elapsed            | 305       |\n",
            "| total timesteps         | 55800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 290      |\n",
            "| fps                     | 182      |\n",
            "| mean 100 episode reward | -247     |\n",
            "| n_updates               | 57600    |\n",
            "| qf1_loss                | 84.57988 |\n",
            "| qf2_loss                | 85.5864  |\n",
            "| time_elapsed            | 315      |\n",
            "| total timesteps         | 57800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 300       |\n",
            "| fps                     | 183       |\n",
            "| mean 100 episode reward | -249      |\n",
            "| n_updates               | 59600     |\n",
            "| qf1_loss                | 65.611855 |\n",
            "| qf2_loss                | 66.24973  |\n",
            "| time_elapsed            | 325       |\n",
            "| total timesteps         | 59800     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| current_lr              | 0.0003     |\n",
            "| episodes                | 310        |\n",
            "| fps                     | 183        |\n",
            "| mean 100 episode reward | -249       |\n",
            "| n_updates               | 61600      |\n",
            "| qf1_loss                | 101.64812  |\n",
            "| qf2_loss                | 102.416595 |\n",
            "| time_elapsed            | 336        |\n",
            "| total timesteps         | 61800      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 320       |\n",
            "| fps                     | 183       |\n",
            "| mean 100 episode reward | -246      |\n",
            "| n_updates               | 63600     |\n",
            "| qf1_loss                | 42.396873 |\n",
            "| qf2_loss                | 43.428898 |\n",
            "| time_elapsed            | 346       |\n",
            "| total timesteps         | 63800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 330       |\n",
            "| fps                     | 184       |\n",
            "| mean 100 episode reward | -238      |\n",
            "| n_updates               | 65600     |\n",
            "| qf1_loss                | 52.225094 |\n",
            "| qf2_loss                | 51.84869  |\n",
            "| time_elapsed            | 357       |\n",
            "| total timesteps         | 65800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 340      |\n",
            "| fps                     | 184      |\n",
            "| mean 100 episode reward | -238     |\n",
            "| n_updates               | 67600    |\n",
            "| qf1_loss                | 45.77497 |\n",
            "| qf2_loss                | 45.59525 |\n",
            "| time_elapsed            | 367      |\n",
            "| total timesteps         | 67800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 350       |\n",
            "| fps                     | 183       |\n",
            "| mean 100 episode reward | -243      |\n",
            "| n_updates               | 69600     |\n",
            "| qf1_loss                | 47.53592  |\n",
            "| qf2_loss                | 47.284718 |\n",
            "| time_elapsed            | 380       |\n",
            "| total timesteps         | 69800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 360       |\n",
            "| fps                     | 184       |\n",
            "| mean 100 episode reward | -246      |\n",
            "| n_updates               | 71600     |\n",
            "| qf1_loss                | 36.252037 |\n",
            "| qf2_loss                | 35.618683 |\n",
            "| time_elapsed            | 390       |\n",
            "| total timesteps         | 71800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 370      |\n",
            "| fps                     | 184      |\n",
            "| mean 100 episode reward | -245     |\n",
            "| n_updates               | 73600    |\n",
            "| qf1_loss                | 35.6091  |\n",
            "| qf2_loss                | 35.19087 |\n",
            "| time_elapsed            | 400      |\n",
            "| total timesteps         | 73800    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 380      |\n",
            "| fps                     | 184      |\n",
            "| mean 100 episode reward | -220     |\n",
            "| n_updates               | 75600    |\n",
            "| qf1_loss                | 9.586972 |\n",
            "| qf2_loss                | 9.073164 |\n",
            "| time_elapsed            | 410      |\n",
            "| total timesteps         | 75800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 390       |\n",
            "| fps                     | 184       |\n",
            "| mean 100 episode reward | -214      |\n",
            "| n_updates               | 77600     |\n",
            "| qf1_loss                | 31.593655 |\n",
            "| qf2_loss                | 31.120913 |\n",
            "| time_elapsed            | 420       |\n",
            "| total timesteps         | 77800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 400       |\n",
            "| fps                     | 185       |\n",
            "| mean 100 episode reward | -216      |\n",
            "| n_updates               | 79600     |\n",
            "| qf1_loss                | 11.027872 |\n",
            "| qf2_loss                | 10.764484 |\n",
            "| time_elapsed            | 430       |\n",
            "| total timesteps         | 79800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 410       |\n",
            "| fps                     | 185       |\n",
            "| mean 100 episode reward | -220      |\n",
            "| n_updates               | 81600     |\n",
            "| qf1_loss                | 25.549194 |\n",
            "| qf2_loss                | 25.14672  |\n",
            "| time_elapsed            | 440       |\n",
            "| total timesteps         | 81800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 420       |\n",
            "| fps                     | 185       |\n",
            "| mean 100 episode reward | -225      |\n",
            "| n_updates               | 83600     |\n",
            "| qf1_loss                | 6.0315537 |\n",
            "| qf2_loss                | 5.813715  |\n",
            "| time_elapsed            | 450       |\n",
            "| total timesteps         | 83800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 430      |\n",
            "| fps                     | 186      |\n",
            "| mean 100 episode reward | -228     |\n",
            "| n_updates               | 85600    |\n",
            "| qf1_loss                | 5.522136 |\n",
            "| qf2_loss                | 5.265089 |\n",
            "| time_elapsed            | 460      |\n",
            "| total timesteps         | 85800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 440       |\n",
            "| fps                     | 186       |\n",
            "| mean 100 episode reward | -231      |\n",
            "| n_updates               | 87600     |\n",
            "| qf1_loss                | 4.8890667 |\n",
            "| qf2_loss                | 4.7916493 |\n",
            "| time_elapsed            | 471       |\n",
            "| total timesteps         | 87800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 450       |\n",
            "| fps                     | 186       |\n",
            "| mean 100 episode reward | -225      |\n",
            "| n_updates               | 89600     |\n",
            "| qf1_loss                | 7.25686   |\n",
            "| qf2_loss                | 7.3131433 |\n",
            "| time_elapsed            | 481       |\n",
            "| total timesteps         | 89800     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 460      |\n",
            "| fps                     | 186      |\n",
            "| mean 100 episode reward | -227     |\n",
            "| n_updates               | 91600    |\n",
            "| qf1_loss                | 9.681335 |\n",
            "| qf2_loss                | 9.835716 |\n",
            "| time_elapsed            | 491      |\n",
            "| total timesteps         | 91800    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| current_lr              | 0.0003   |\n",
            "| episodes                | 470      |\n",
            "| fps                     | 186      |\n",
            "| mean 100 episode reward | -220     |\n",
            "| n_updates               | 93600    |\n",
            "| qf1_loss                | 8.056425 |\n",
            "| qf2_loss                | 7.905852 |\n",
            "| time_elapsed            | 501      |\n",
            "| total timesteps         | 93800    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 480       |\n",
            "| fps                     | 187       |\n",
            "| mean 100 episode reward | -225      |\n",
            "| n_updates               | 95600     |\n",
            "| qf1_loss                | 6.8814673 |\n",
            "| qf2_loss                | 6.991045  |\n",
            "| time_elapsed            | 512       |\n",
            "| total timesteps         | 95800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 490       |\n",
            "| fps                     | 186       |\n",
            "| mean 100 episode reward | -229      |\n",
            "| n_updates               | 97600     |\n",
            "| qf1_loss                | 7.569992  |\n",
            "| qf2_loss                | 7.6920223 |\n",
            "| time_elapsed            | 523       |\n",
            "| total timesteps         | 97800     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| current_lr              | 0.0003    |\n",
            "| episodes                | 500       |\n",
            "| fps                     | 186       |\n",
            "| mean 100 episode reward | -221      |\n",
            "| n_updates               | 99600     |\n",
            "| qf1_loss                | 7.2161975 |\n",
            "| qf2_loss                | 7.3999944 |\n",
            "| time_elapsed            | 534       |\n",
            "| total timesteps         | 99800     |\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGy7zG0KWN4o",
        "colab_type": "text"
      },
      "source": [
        "##Launching TensorBoard to evaluate learing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz11QSsqmODB",
        "colab_type": "code",
        "outputId": "57e37ead-eece-4f5c-8cc4-ad08b7e98302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Launch TensorBoard after learning\n",
        "#%tensorboard --logdir /content/drive/My\\ Drive/DLSeminar/models/AntBulletEnv-v0/logs/\n",
        "%tensorboard --logdir /content/drive/My\\ Drive/DLSeminar/models/Pendulum-v0/logs/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 5338), started 0:42:30 ago. (Use '!kill 5338' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}